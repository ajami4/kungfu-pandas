{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Progress Report\n",
    "<h1 style=\"font-size: 14px\"><I>Team KungFu Pandas: Raj Patel, Ayush Jamindar, Amrita Rajesh, Saloni Mhatre, Lakshmi Krishna</I></h1>\n",
    "<div><img src= 'https://cdna.artstation.com/p/assets/images/images/037/325/102/medium/haengsook-oh-baby-po.jpg?1620094956' width=100></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Project Introduction\n",
    "\n",
    "<h6 style='font-size : 12px'>\n",
    "We are analyzing on the crime dataset and housing dataset. The crime dataset and housing dataset are publicly available at :\n",
    "\n",
    "- Chicago Crime Data Source: https://data.cityofchicago.org/Public-Safety/Crimes-2001-to-Present/ijzp-q8t2/about_data\n",
    "- Zillow Data Source: https://www.zillow.com/research/data/\n",
    "\n",
    "Questions that we are investigating are `is there coorelationship between Housing prices and Crime in Chicago?`, `Which Neighborhood is not the safest to move in?`, `Has the Crime increased after post covid compare to Pre Covid?`, `Most common type of crime committed in Chicago area`\n",
    "</h6>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Any Changes\n",
    "<p style=\"font-size:12px\">\n",
    "We have added a new dataset to our project, \"Housing Dataset\". We will use this dataset to answer our question. For instance, is there correlation between housing prices and crime activity?\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5 style=\"font-size: 16px\">\n",
    "\n",
    "`IMPORTANT NOTE`: \n",
    "</h5>\n",
    "\n",
    "<h1 style=\"font-size: 14px\">\n",
    "Please create a folder called `csv_files`. This will contain all the CSV files so after downloading the data, please put it in this folder.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from CleaningPR import *\n",
    "from ML_pr import *\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Cleaning Process\n",
    "<!-- <div><img src= 'https://cdn-icons-png.flaticon.com/512/10179/10179118.png' width=100></div> -->\n",
    "<h6 style=\"font-size: 12px\">\n",
    "This process contains the necessary steps like getting the data info such as data size, number of features, number of records, mean value, max value, etc. This step also includes dropping some columns and rows, adding more information, joining the dataframes and storing them into seperate CSV files for easier access in the future.\n",
    "Crime Dataset Information and Cleaning\n",
    "\n",
    "- This the crime data that we have accquired from the above link and it shows information about the crimes that took place in chicago from `January 2001` to `February 2024`\n",
    "- Granularity: Each row in this data represents individual crime that has been reported with specs about each crime such as ID, Case Number, Date etc.\n",
    "- Contains `~8 million` records\n",
    "- steps\n",
    "    1) Converting the Date\n",
    "    2) Dropping the unecessary columns\n",
    "    3) Filtering\n",
    "    4) Saving the Dataframe to a CSV file (`Crimes_2017_to_2019.csv`, `Crimes_2021_to_Present.csv`, `Crimes_2014.csv`)\n",
    "    </h6>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "crime_data = pd.read_csv('csv_files/Crimes_2001_to_Present.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns:  ['ID', 'New_Date', 'Primary Type', 'Location Description', 'Arrest', 'Community Area', 'RegionName']\n",
      "Pre Covid Min new_date value:  2017-01-01 00:00:00\n",
      "Pre Covid Max new_date value:  2019-12-31 23:55:00\n",
      "\n",
      "Post Covid Min new_date value:  2021-01-01 00:00:00\n",
      "Post Covid Max new_date value:  2024-02-10 00:00:00\n",
      "\n",
      "Decade Crime Min new_date value:  2014-01-01 00:00:00\n",
      "Decade Crime Max new_date value:  2024-02-10 00:00:00\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "    cleanCrimeData method will perform Step 1,2,3 and 4.\n",
    "    if want to see the cleaned version of pre-covid, post-covid crime data and decade crime data\n",
    "    then try opening and printing the head of `Crimes_2017_to_2019.csv`, `Crimes_2021_to_Present.csv`, `Crimes_2014.csv`\n",
    "'''\n",
    "cleanCrimeData(crime_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"font-size: 16px\"> Neighborhood Dataset Information and Cleaning </h1>\n",
    "<h1 style=\"font-size: 12px\">\n",
    "\n",
    "- The data we have acquired is from zillow and it shows the average house price for each nighborhood in the country\n",
    "- Granularity: Each row represents a neighborhood in a state and shows the average house price for each month from `1-31-2000` to `1-31-2024`\n",
    "- Contains average monthly prices for real estate of around `~21000` neighborhoods across the U.S.\n",
    "- Steps\n",
    "    1) Filtering\n",
    "    - Extract data only from neighborhoods in Chicago. \n",
    "    2) Transposing the Data\n",
    "    - Reseting the index, rotating the dataframe so that neighborhoods are now columns each row for the column\n",
    "    is the average property price for each month. \n",
    "    This makes it easier to read the dataframe and perform aggregate functions.\n",
    "    3) Saving the DataFrame (`neighborhood_data_2017_to_2019.csv`, `neighborhood_data_2021_present.csv`)\n",
    "</h1 >"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "neighborhood_data = pd.read_csv('csv_files/Neighborhood_House_Price.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "    cleanHousingData method will perform Step 1,2,and 3. \n",
    "    if want to see the cleaned version of pre-covid and post-covid data then \n",
    "    try opening and printing the head of `neighborhood_data_2017_to_2019.csv`, `neighborhood_data_2021_present.csv`\n",
    "'''\n",
    "cleanHousingData(neighborhood_data) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exploratory Data Analysis\n",
    "<!-- <div><img src= 'https://cdn-blog.scalablepath.com/uploads/2021/06/exploratory-data-analysis-900x615-1.png' width=100></div> -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualizations\n",
    "<!-- <div><img src= 'https://media.sproutsocial.com/uploads/2023/10/Data-Visualization-Final.jpg' width=100></div> -->\n",
    "(Amrita and Saloni put your work here)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Machine Learning\n",
    "<h1 style=\"font-size: 12px\">\n",
    "Using supervised learning model, predict the probability of a person getting arrested given primary type of crime, location description and neighborhood(region name)\n",
    "\n",
    "<b>Step 1</b>: Spliting\n",
    "\n",
    "- Splitting the data into testing and training set using the decade crime data(`crime_data_2014.csv`). TO BE CAUTIOUS ABOUT NOT TOUCHING THE TESTING DATA.\n",
    "    \n",
    "<b>Step 2</b>: Best Feature\n",
    "\n",
    "- Get the feature(s) which will give us the best accuracy (i.e only primary type, only primary type and RegionName and so on).\n",
    "    The feature_selection_and_evaluation() function uses logistic regression model to get the best paramters.\n",
    "    1) We use and encoder to change the string variables to 0s and 1s to make it easiser to fit and train the model\n",
    "    2) We use k-cross validation to split into a K number of folds and is used to evaluate the model's ability when given new data to test our parameters\n",
    "    3) Use logistic regression to fit and predict using the training data (~2 million entries)\n",
    "    4) Return the best accuracy and the parameters for that accuracy\n",
    "\n",
    "<b>Step 3</b>: Comparsion with baseline model which uses mode to predict the value\n",
    "- Using Primary Type, Location Description, RegionName as input parameters for our logistic regression model we get an 87% accuracy. Comparing this to the baseline model which uses mode to predict the possibility of an arrest we get 80% accuracy. There is a 7% accuracy growth when using the Logistic Regression. Also note that our model is not under or overfitting since it is not 100% accurate nor 40-60% accurate\n",
    "\n",
    "<b>Step 4</b>: Training/Testing the model\n",
    "\n",
    "- Using the best feature that we got from best_feature() function, train the LogisticRegression Model using the same training set as earlier to avoid making new one\n",
    "    1) Training the model\n",
    "    2) Test the model\n",
    "    3) Create new dataframe\n",
    "\n",
    "</h1>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of the training dataset 2008524\n",
      "Best Features ['Primary Type', 'Location Description', 'RegionName'] Accuracy of Logistic Regression:  0.8786626398290486\n",
      "Accuracy of the baseline model:  0.8083941242424786\n",
      "Accuracy: 0.8786813029243307\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Primary Type</th>\n",
       "      <th>Location Description</th>\n",
       "      <th>RegionName</th>\n",
       "      <th>Prob</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2178855</th>\n",
       "      <td>THEFT</td>\n",
       "      <td>SIDEWALK</td>\n",
       "      <td>Loop</td>\n",
       "      <td>0.071569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1869478</th>\n",
       "      <td>ASSAULT</td>\n",
       "      <td>ALLEY</td>\n",
       "      <td>Lake View</td>\n",
       "      <td>0.112263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1299827</th>\n",
       "      <td>THEFT</td>\n",
       "      <td>SIDEWALK</td>\n",
       "      <td>Englewood</td>\n",
       "      <td>0.076977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1024670</th>\n",
       "      <td>THEFT</td>\n",
       "      <td>SIDEWALK</td>\n",
       "      <td>West Town</td>\n",
       "      <td>0.054855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>229033</th>\n",
       "      <td>BATTERY</td>\n",
       "      <td>STREET</td>\n",
       "      <td>Near South Side</td>\n",
       "      <td>0.200903</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Primary Type Location Description       RegionName      Prob\n",
       "2178855        THEFT             SIDEWALK             Loop  0.071569\n",
       "1869478      ASSAULT                ALLEY        Lake View  0.112263\n",
       "1299827        THEFT             SIDEWALK        Englewood  0.076977\n",
       "1024670        THEFT             SIDEWALK        West Town  0.054855\n",
       "229033       BATTERY               STREET  Near South Side  0.200903"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "crime_data_2014 = pd.read_csv('csv_files/Crimes_2014.csv')\n",
    "'''\n",
    "    Step 1: Spliting\n",
    "'''\n",
    "X = crime_data_2014[['Primary Type', 'Location Description', 'RegionName']]\n",
    "y = crime_data_2014['Arrest'] \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42) # 80% training, 20% testing\n",
    "print(\"length of the training dataset\",len(X_train))\n",
    "\n",
    "'''\n",
    "    best_feature method will perform step 2 and 3\n",
    "'''\n",
    "feature = best_feature(crime_data_2014, X_train, y_train)\n",
    "\n",
    "''' train_test method will perform step 4 '''\n",
    "train_test(X_train, X_test, y_train, y_test, feature) # Uses Logistic Regression Model to train and test our model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Step 5</b>: Model Usage\n",
    "\n",
    "<h1 style=\"font-size:12px\">\n",
    "\n",
    "Firstly we trained our model using the crime data from the past decade(2014-present) so that it can learn as much as possible. Then our stakeholder `Residents of Chicago, UIC students, new settlers and Chicago Police Department` can predict the probabilty of a person getting arrested based on the type of crime, neighborhood, and discription of the location. Our model will not give 100% accuracy on the prediction but it will predict the outcome 87.86% of the time correctly. In other terms, it be able to predict about 4 out of 5 outcomes correctly </h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reflection\n",
    "<h1 style=\"font-size: 12px\">\n",
    "<i>What is hardest part of the project that you’ve encountered so far?</i>\n",
    "\n",
    "- The hardest part of this project was to understand the data, clean the data and how we can the housing dataset and crime dataset to come up with hypothesis. Second hardest part was to determine how our Machine Learning model can be useful to the stakeholder becasue ML model gives us the prediction, it's us who will determine how we can use it to solve our problem.\n",
    "\n",
    "<i>What are your initial insights?</i>\n",
    "- nothing\n",
    "\n",
    "<i>Are there any concrete results you can show at this point? If not, why not?</i>\n",
    "- Yes, We can show concrete results with our visualization. (Talk more about visulization)\n",
    "\n",
    "<i>Going forward, what are the current biggest problems you’re facing?</i>\n",
    "- The biggest problem we are facing is the merging of Housing Dataset and Crime Dataset since there are some neighborhoods which are in Housing Data but not in the Crime dataset while there are some neighborhoods which are in Crime Dataset but no in Housing Dataset.\n",
    "\n",
    "<i>Do you think you are on track with your project? If not, what parts do you need to dedicate more time to?</i>\n",
    "- Yes, we set a personal due date for this project progess and we managed to finished all the parts efficiently\n",
    "\n",
    "<i>Given your initial exploration of the data, is it worth proceeding with your project, why? If not, how are you going to change your project and why do you think it’s better than your current results?</i>\n",
    "\n",
    "- Yes, we have all the necessary information to do ML/Stats, Test our hypothesis, Come up with interesting finding and more\n",
    "</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Next Step\n",
    "<!-- <div><img src= 'https://www.pocketmindfulness.com/wp-content/uploads/2017/03/baby-steps-approach.jpg' width=100></div> -->\n",
    "<h1 style = \"font-size: 12px\">\n",
    "\n",
    "<i>What you plan to accomplish in the next month and how you plan to evaluate whether your project achieved the goals you set for it.<i>\n",
    "- We are planning to do T-Test on our hypothesis `There has been increase in crime after post covid` and to decide whether to reject or fail to reject the null hypothesis. We will try to create another ML model where we will include the neighborhood average housing price to predict the chances of offender being arrest. On top of this, we will also try to discover more interesting finding using visualization with the help of our EDA\n",
    "\n",
    "- We will `split the work` accordingly amongs the team member using GitHub Kanban board so there is a nice workflow and line of communication. We will also set a `personal due date` like a week before the actual project due date so we can resolve any lossends\n",
    "</h1>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cs418env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
